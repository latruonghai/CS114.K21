{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "#Dùng time để truy cập các URL với startTime khác nhau\n",
    "# Ví dụ: https://sports.theonion.com/?startTime=1585067580290\n",
    "time = [1591289220194,1589395680468,1588268460533,1588271100468,\n",
    "        1587140580419,1585163880765,1583849340543,1580220000317,\n",
    "       1582814880415,1581523200230,1580212800340,1588360800834,1585067580290]\n",
    "url = 'https://local.theonion.com/?startTime='\n",
    "#Lấy file '.html' từ url đích\n",
    "def get_page_content(url):\n",
    "    page = requests.get(url,headers={\"Accept-Language\":\"en-US\"})\n",
    "    return bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "#Đọc file '.html' trong trường hợp HTTP secured\n",
    "\"\"\"def DocFile(path):\n",
    "    file=codecs.open(path,\"r\")\n",
    "    file1=file.read()\n",
    "    file1=str(file1)\n",
    "    soup = bs4.BeautifulSoup(file1,'html.parser')\n",
    "    return soup\"\"\"\n",
    "#quét text html\n",
    "def parse(soup):\n",
    "    article = soup.findAll('div',class_=\"cw4lnv-11 dFCKPx\")\n",
    "    links = [art.find('a') for art in article]\n",
    "    link = []\n",
    "    #get links_article\n",
    "    for l in links:\n",
    "        link.append(l.get('href'))\n",
    "    headlines = [head.find('h2',class_=\"sc-759qgu-0 cYlVdn cw4lnv-6 eXwNRE\").text for head in article]\n",
    "    return link, headlines\n",
    "\n",
    "#Chuyển tẽxt trên thành DataFrame\n",
    "def get_df(link,headlines):\n",
    "    papers = {\"Article\":link, \"Headlines\":headlines,\"is_sarcasm\":[1-1]*len(link)}\n",
    "    data = pd.DataFrame(papers)\n",
    "    return data\n",
    "    #data.to_csv('sarcasm.csv', header = True, index = None)\n",
    "    \n",
    "#Đưa DF về csv\n",
    "def get_csv(listdata):\n",
    "    data = listdata[0]\n",
    "    for i in range(1,len(listdata)):\n",
    "        data = data.append(listdata[i])\n",
    "    result = data.to_csv(\"sarcasm_onion2.csv\",header = True, index = None)\n",
    "\n",
    "#Bắt đầu quét nhiều URL với lists là tập các link cần quét    \n",
    "def Sarcasm(lists):\n",
    "    for arg in lists:\n",
    "        soup = get_page_content(arg)\n",
    "        link,headlines = parse(soup)\n",
    "        data = get_df(link,headlines)\n",
    "        \n",
    "        yield data\n",
    "#Tìm tất cả các link có thể có trong URL chủ\n",
    "def get_link(soup):\n",
    "    for b in soup:\n",
    "        temp = str(b.get('href'))\n",
    "        if temp.find('https')>-1 and temp.find('entertainment')<0:\n",
    "            yield temp\n",
    "#Tại URL:\"https://www.theonion.com/\" get link tất cả URL\n",
    "#có className = \"sc-1out364-0 hMndXN a1de4o-0 a1de4o-1 irneHt js_link\"\n",
    "#tức là các tab (đề mục) trên trang chủ.\n",
    "links = list(get_link(get_page_content(\"https://www.theonion.com/\").findAll('a',\n",
    "            class_=\"sc-1out364-0 hMndXN a1de4o-0 a1de4o-1 irneHt js_link\")))\n",
    "#print(links)\n",
    "#Với mỗi link được tạo ra sau khi get link\n",
    "#tạo ra một url mới với mục đích crawl nhiều tên miền ở nhiều thời điểm khác nhau\n",
    "#(kết hợp với list time)\n",
    "lists = [string +'/?startTime='+ str(i) for i in time for string in links]\n",
    "#print(lists)\n",
    "#Tạo list với nhiều tên miền khác nhau.\n",
    "#Sau đó tạo DF\n",
    "listada = list(Sarcasm(lists))\n",
    "#Chuyển DF về csv\n",
    "result = get_csv(listada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv(\"sarcasm_onion2.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: is_sarcasm, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['is_sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacra = pd.read_csv(\"sarcasms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "995    1\n",
       "996    1\n",
       "997    1\n",
       "998    1\n",
       "999    1\n",
       "Name: is_sarcasm, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sacra['is_sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm = sacra.append(db,sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm.to_csv(\"nlp_sarcasm.csv\", index = None, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: is_sarcasm, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm['is_sarcasm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.read_csv(\"nlp_sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1995    0\n",
       "1996    0\n",
       "1997    0\n",
       "1998    0\n",
       "1999    0\n",
       "Name: is_sarcasm, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['is_sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('foo': conda)",
   "language": "python",
   "name": "python38364bitfoocondaa93fb2234420416a9eaa26ad5f935624"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
